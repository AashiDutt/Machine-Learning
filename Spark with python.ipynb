{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARK WITH PYTHON \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark is used to quickly and easily handle Big Data.\n",
    "* it is an open source project on Apache\n",
    "\n",
    "**Spark uses Amazon Web Services a we cannot work with Big Data on local system thus AWS gives distributed system to work on Big Data.**\n",
    "\n",
    "* Spark is an alternative to MapReduce.\n",
    "* MapReduce requires its files to be stored in Hadoop Distribution File System(HDFS), but Spark does not require.\n",
    "* Spark can perforn its tasks 100 times moe quickly than MapReduce.\n",
    "\n",
    "**How Spark gains its speed from??**\n",
    "Spark keeps most of its data in memory after each transformation.Spark can spill over to disk if memory is full.\n",
    "\n",
    "\n",
    "Spark core is the idea of Resilient Distributed Dataset(RDD)\n",
    "\n",
    "Resilient Distribution Dataset has 4 features :\n",
    "\n",
    " * Distributed Collection of Data.\n",
    " * Fault - Tolerant \n",
    " * Parallel operation - Partitioned\n",
    " * Ability to use many data sources\n",
    " \n",
    " \n",
    " **There are 2 types of RDD Operations **\n",
    " \n",
    " * Transformations \n",
    " * Actions\n",
    " \n",
    " **Basic Actions are :\n",
    " \n",
    " * First\n",
    " * Collect \n",
    " * Count \n",
    " * Take\n",
    " \n",
    " * Collect - Return all the elments of the RDD as an array at the driver program.\n",
    " * Count - Return the number of elements in the RDD.\n",
    " * First - return the first element in RDD.\n",
    " * Take - Return an array with the first n elements of RDD.\n",
    " \n",
    " **Basic Transformations**\n",
    " \n",
    " * Filter\n",
    " * Map\n",
    " * FlatMap\n",
    " \n",
    " RDD.filter() - applies a function to each element and returns elements that evaluate to true.\n",
    " RDD.Map() - transforms each element and preserves same no. of elements ,very similar idea to pandas.apply()\n",
    " RDD.flatMap() -transforms each element into 0 to N elements and changes no. of elements .\n",
    " \n",
    " Reduce() - an action that will aggregate RDD elements using a function that returns a single element.\n",
    " ReduceByKey() - an action that will aggregate pair RDD elements by using a function that returns a Pair RDD.\n",
    " (**Similar as GroupBy operation)\n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
